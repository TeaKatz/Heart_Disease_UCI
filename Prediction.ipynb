{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"dataset/heart.csv\"\n",
    "CONTINIOUS_ATTRIBUTES = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "DISCRETE_ATTRIBUTES = [\"cp\", \"restecg\", \"slope\", \"ca\", \"thal\"]\n",
    "BINARY_ATTRIBUTES = [\"sex\", \"fbs\", \"exang\", \"target\"]\n",
    "\n",
    "data = pd.read_csv(DATA_DIR)\n",
    "data.loc[:, CONTINIOUS_ATTRIBUTES] = data.loc[:, CONTINIOUS_ATTRIBUTES].astype(\"float64\", copy=False)\n",
    "data.loc[:, DISCRETE_ATTRIBUTES] = data.loc[:, DISCRETE_ATTRIBUTES].astype(\"int8\", copy=False)\n",
    "data.loc[:, BINARY_ATTRIBUTES] = data.loc[:, BINARY_ATTRIBUTES].astype(\"int8\", copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null float64\n",
      "sex         303 non-null int8\n",
      "cp          303 non-null int8\n",
      "trestbps    303 non-null float64\n",
      "chol        303 non-null float64\n",
      "fbs         303 non-null int8\n",
      "restecg     303 non-null int8\n",
      "thalach     303 non-null float64\n",
      "exang       303 non-null int8\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int8\n",
      "ca          303 non-null int8\n",
      "thal        303 non-null int8\n",
      "target      303 non-null int8\n",
      "dtypes: float64(5), int8(9)\n",
      "memory usage: 14.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=100, stratify=data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're gonna use cross validation, we cannot normalize train data beforehand, \n",
    "# instead, we will normalize train-validation data on the go while training.\n",
    "def normalize(train_set, test_set, attributes=None):\n",
    "    \"\"\"\n",
    "    If attributes is not define, then, all attributes will be apply.\n",
    "    \"\"\"\n",
    "    if attributes is not None:\n",
    "        _train_set = train_set.loc[:, attributes]\n",
    "        _test_set = test_set.loc[:, attributes]\n",
    "    else:\n",
    "        _train_set = train_set\n",
    "        _test_set = test_set\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(_train_set)\n",
    "    \n",
    "    if attributes is not None:\n",
    "        train_set.loc[:, attributes] = scaler.transform(_train_set)\n",
    "        test_set.loc[:, attributes] = scaler.transform(_test_set)\n",
    "    else:\n",
    "        train_set = scaler.transform(_train_set)\n",
    "        test_set = scaler.transform(_test_set)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoder\n",
    "def encode(train_set, test_set, attributes=None):\n",
    "    \"\"\"\n",
    "    If attributes is not define, then, all attributes will be apply.\n",
    "    \"\"\"\n",
    "    if attributes is not None:\n",
    "        _train_set = train_set.loc[:, attributes]\n",
    "        _test_set = test_set.loc[:, attributes]\n",
    "    else:\n",
    "        _train_set = train_set\n",
    "        _test_set = test_set\n",
    "        \n",
    "    encoder = OneHotEncoder(categories=\"auto\", drop=\"first\")\n",
    "    encoder.fit(_train_set)\n",
    "    \n",
    "    _train_set = encoder.transform(_train_set)\n",
    "    _test_set = encoder.transform(_test_set)\n",
    "    \n",
    "    \n",
    "    if attributes is not None:\n",
    "        _train_set = pd.DataFrame(_train_set.toarray(), columns=encoder.get_feature_names(attributes), index=train_set.index)\n",
    "        _test_set = pd.DataFrame(_test_set.toarray(), columns=encoder.get_feature_names(attributes), index=test_set.index)\n",
    "\n",
    "        train_set = pd.concat([train_set.drop(attributes, axis=1), _train_set], axis=1, sort=False)\n",
    "        test_set = pd.concat([test_set.drop(attributes, axis=1), _test_set], axis=1, sort=False)\n",
    "    else:\n",
    "        train_set = _train_set\n",
    "        test_set = _test_set\n",
    "        \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_prepared, test_prepared = normalize(train_set, test_set, attributes=CONTINIOUS_ATTRIBUTES)\n",
    "train_prepared, test_prepared = encode(train_prepared, test_prepared, attributes=DISCRETE_ATTRIBUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X-Y\n",
    "train_X, train_Y = train_prepared.drop(\"target\", axis=1).values, train_prepared.loc[:, \"target\"].values\n",
    "test_X, test_Y = test_prepared.drop(\"target\", axis=1).values, test_prepared.loc[:, \"target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers, optimizers\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(nodes=[8], optimizer=\"RMSprop\", epochs=200, batch_size=32):\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kfold.split(train_X, train_Y):\n",
    "        # create model\n",
    "        model = build_model(nodes)\n",
    "        # Compile model\n",
    "        model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "        # Fit the model\n",
    "        model.fit(train_X[train_index], train_Y[train_index], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        # Evaluate the model\n",
    "        scores = model.evaluate(train_X[val_index], train_Y[val_index], verbose=0)\n",
    "        val_scores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(val_scores), np.std(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(nodes=[8]):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(nodes[0], activation=\"relu\", input_shape=(train_X.shape[-1], )))\n",
    "    for i in range(len(nodes) - 1):\n",
    "        model.add(layers.Dense(nodes[i], activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.23% (+/- 8.88%)\n",
      "------------------------------------\n",
      "81.30% (+/- 10.25%)\n",
      "------------------------------------\n",
      "80.28% (+/- 6.73%)\n",
      "------------------------------------\n",
      "80.78% (+/- 10.36%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary node size\n",
    "nodes = [[8], [8, 8], [8, 8, 8], [8 ,8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _nodes in nodes:\n",
    "    model_evaluate(_nodes, optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "84.30% (+/- 9.26%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary number of nodes\n",
    "nodes = [[8], [8, 8], [8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _nodes in nodes:\n",
    "    model_evaluate(_nodes, optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "84.30% (+/- 9.26%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary optimizers\n",
    "nodes = [[8], [8, 8], [8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _optimizer in optimizer:\n",
    "    model_evaluate(nodes, _optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "84.30% (+/- 9.26%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary learning rate\n",
    "nodes = [[8], [8, 8], [8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _optimizer in optimizer:\n",
    "    model_evaluate(nodes, _optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
