{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"dataset/heart.csv\"\n",
    "CONTINIOUS_ATTRIBUTES = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "DISCRETE_ATTRIBUTES = [\"cp\", \"restecg\", \"slope\", \"ca\", \"thal\"]\n",
    "BINARY_ATTRIBUTES = [\"sex\", \"fbs\", \"exang\", \"target\"]\n",
    "\n",
    "data = pd.read_csv(DATA_DIR)\n",
    "data.loc[:, CONTINIOUS_ATTRIBUTES] = data.loc[:, CONTINIOUS_ATTRIBUTES].astype(\"float64\", copy=False)\n",
    "data.loc[:, DISCRETE_ATTRIBUTES] = data.loc[:, DISCRETE_ATTRIBUTES].astype(\"int8\", copy=False)\n",
    "data.loc[:, BINARY_ATTRIBUTES] = data.loc[:, BINARY_ATTRIBUTES].astype(\"int8\", copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null float64\n",
      "sex         303 non-null int8\n",
      "cp          303 non-null int8\n",
      "trestbps    303 non-null float64\n",
      "chol        303 non-null float64\n",
      "fbs         303 non-null int8\n",
      "restecg     303 non-null int8\n",
      "thalach     303 non-null float64\n",
      "exang       303 non-null int8\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int8\n",
      "ca          303 non-null int8\n",
      "thal        303 non-null int8\n",
      "target      303 non-null int8\n",
      "dtypes: float64(5), int8(9)\n",
      "memory usage: 14.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=100, stratify=data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're gonna use cross validation, we cannot normalize train data beforehand, \n",
    "# instead, we will normalize train-validation data on the go while training.\n",
    "def normalize(train_set, test_set, attributes=None):\n",
    "    \"\"\"\n",
    "    If attributes is not define, then, all attributes will be apply.\n",
    "    \"\"\"\n",
    "    if attributes is not None:\n",
    "        _train_set = train_set.loc[:, attributes]\n",
    "        _test_set = test_set.loc[:, attributes]\n",
    "    else:\n",
    "        _train_set = train_set\n",
    "        _test_set = test_set\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(_train_set)\n",
    "    \n",
    "    if attributes is not None:\n",
    "        train_set.loc[:, attributes] = scaler.transform(_train_set)\n",
    "        test_set.loc[:, attributes] = scaler.transform(_test_set)\n",
    "    else:\n",
    "        train_set = scaler.transform(_train_set)\n",
    "        test_set = scaler.transform(_test_set)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoder\n",
    "def encode(train_set, test_set, attributes=None):\n",
    "    \"\"\"\n",
    "    If attributes is not define, then, all attributes will be apply.\n",
    "    \"\"\"\n",
    "    if attributes is not None:\n",
    "        _train_set = train_set.loc[:, attributes]\n",
    "        _test_set = test_set.loc[:, attributes]\n",
    "    else:\n",
    "        _train_set = train_set\n",
    "        _test_set = test_set\n",
    "        \n",
    "    encoder = OneHotEncoder(categories=\"auto\", drop=\"first\")\n",
    "    encoder.fit(_train_set)\n",
    "    \n",
    "    _train_set = encoder.transform(_train_set)\n",
    "    _test_set = encoder.transform(_test_set)\n",
    "    \n",
    "    if attributes is not None:\n",
    "        _train_set = pd.DataFrame(_train_set.toarray(), columns=encoder.get_feature_names(attributes), index=train_set.index)\n",
    "        _test_set = pd.DataFrame(_test_set.toarray(), columns=encoder.get_feature_names(attributes), index=test_set.index)\n",
    "\n",
    "        train_set = pd.concat([train_set.drop(attributes, axis=1), _train_set], axis=1, sort=False)\n",
    "        test_set = pd.concat([test_set.drop(attributes, axis=1), _test_set], axis=1, sort=False)\n",
    "    else:\n",
    "        train_set = _train_set\n",
    "        test_set = _test_set\n",
    "        \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared, test_prepared = encode(train_set, test_set, attributes=DISCRETE_ATTRIBUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X-Y\n",
    "train_X, train_Y = train_prepared.drop(\"target\", axis=1).reset_index(drop=True), train_prepared.loc[:, \"target\"].reset_index(drop=True)\n",
    "test_X, test_Y = test_prepared.drop(\"target\", axis=1).reset_index(drop=True), test_prepared.loc[:, \"target\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers, optimizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(nodes=[8], optimizer=\"RMSprop\", epochs=200, batch_size=32):\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kfold.split(train_X, train_Y):\n",
    "        # Get train data\n",
    "        _train_X, _train_Y = train_X.iloc[train_index], train_Y.iloc[train_index]\n",
    "        # Get validation data\n",
    "        _val_X, _val_Y = train_X.iloc[val_index], train_Y.iloc[val_index]\n",
    "        \n",
    "        # Normalization\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(_train_X.loc[:, CONTINIOUS_ATTRIBUTES])\n",
    "        \n",
    "        _train_X.loc[:, CONTINIOUS_ATTRIBUTES] = scaler.transform(_train_X.loc[:, CONTINIOUS_ATTRIBUTES])\n",
    "        _val_X.loc[:, CONTINIOUS_ATTRIBUTES] = scaler.transform(_val_X.loc[:, CONTINIOUS_ATTRIBUTES])\n",
    "        \n",
    "        # create model\n",
    "        model = build_model(input_shape=(_train_X.shape[-1], ), nodes=nodes)\n",
    "        # Compile model\n",
    "        model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "        # Fit the model\n",
    "        model.fit(_train_X, _train_Y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        # Evaluate the model\n",
    "        scores = model.evaluate(_val_X, _val_Y, verbose=0)\n",
    "        val_scores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(val_scores), np.std(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, nodes=[8]):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(nodes[0], activation=\"relu\", input_shape=input_shape))\n",
    "    for i in range(len(nodes) - 1):\n",
    "        model.add(layers.Dense(nodes[i], activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.14% (+/- 11.37%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary node size\n",
    "nodes = [[1], [2], [4], [8], [16], [32], [64], [128]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _nodes in nodes:\n",
    "    model_evaluate(_nodes, optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------{}\".format(_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multiclass-multioutput' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9f3bae550fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_nodes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-4bf851b1f372>\u001b[0m in \u001b[0;36mmodel_evaluate\u001b[0;34m(nodes, optimizer, epochs, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Get train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    639\u001b[0m             raise ValueError(\n\u001b[1;32m    640\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[0;32m--> 641\u001b[0;31m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multiclass-multioutput' instead."
     ]
    }
   ],
   "source": [
    "# Vary number of nodes\n",
    "nodes = [[8], [8, 8], [8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _nodes in nodes:\n",
    "    model_evaluate(_nodes, optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "84.30% (+/- 9.26%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary optimizers\n",
    "nodes = [[8], [8, 8], [8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _optimizer in optimizer:\n",
    "    model_evaluate(nodes, _optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "84.30% (+/- 9.26%)\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Vary learning rate\n",
    "nodes = [[8], [8, 8], [8, 8, 8]]\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "for _optimizer in optimizer:\n",
    "    model_evaluate(nodes, _optimizer, epochs, batch_size)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
